---
mathjax: true
tag: Probability
excerpt: sheet 3 ‚Äî MT 2022
---
<style>div.noprint{border: solid 1px black;padding: 5px; width: max-content;max-width: 99%;}.q{background-color: lightcyan;}
    #main>li{page-break-after: always;}</style>
<ol id="main">
<li>
    <div class="q">
        Find the communicating classes of Markov chains with the following transition matrices on the state space $\{1,2,3,4,5\}$, and in each case determine which classes are closed:
        \[\text{(i) }\begin{pmatrix}\frac12 & 0 & 0 & 0 &\frac12\\ 0 &\frac12& 0 &\frac12& 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 &\frac14&\frac14&\frac14&\frac14\\\frac12& 0 & 0 & 0 &\frac12\end{pmatrix}‚ÄÉ
        \text{(ii) }\begin{pmatrix}\frac14 & 0 &\frac34& 0 & 0 \\ 0 &\frac13& 0 &\frac23& 0 \\ 0 & 0 &\frac12& 0 &\frac12\\\frac12&\frac16& 0 &\frac13& 0 \\\frac14& 0 &\frac12& 0 &\frac14\end{pmatrix}\]
        If $X$ is a chain with the transition matrix in (ii), find the distribution of $X_1$ when $X_0$ has the uniform distribution on $\{1,2,3,4,5\}$, and find $P\left(X_2=3‚à£X_0=1\right)$.
    </div>
    <div class="noprint">communicating class for markov chain ‚â° connected component for directed graph</div>
<table>
<tr><td>(i) communicating classes: $\{1,5\},\{3\}$ are closed, $\{2,4\}$ is open.<br>
{% latex %}\usepackage{tikz}\usetikzlibrary {arrows.meta,automata,positioning}
\begin{tikzpicture}
\node[state](q_1) {$1$};
\node[state](q_5) [right=of q_1] {$5$};
\node[state](q_4) [right=of q_5] {$4$};
\node[state](q_2) [right=of q_4] {$2$};
\node[state](q_3) [below=of q_4] {$3$};
\path[->,>={Stealth[round]}] (q_5) edge[<->] (q_1) edge [loop above]()
(q_1) edge [loop above]()
(q_3) edge [loop below]()
(q_4) edge[<->] (q_2) edge (q_3) edge (q_5) edge [loop above]()
(q_2) edge [loop above]();
\end{tikzpicture}
{% endlatex %}
</td></tr><tr><td>(ii) communicating class: $\{1,3,5\}$ is closed, $\{2,4\}$ is open.<br>
{% latex %}\usepackage{tikz}
\usetikzlibrary {arrows.meta,automata,positioning}
\begin{tikzpicture}
\node[state](q_1) {$1$};
\node[state](q_4) [left=of q_1] {$4$};
\node[state](q_3) [below right=of q_1] {$3$};
\node[state](q_5) [above right=of q_1] {$5$};
\node[state](q_2) [left=of q_4]{$2$};
\path[->,>={Stealth[round]}] (q_1) edge (q_3) edge [loop above]()
(q_2) edge[<->] (q_4) edge [loop above]()
(q_3) edge[<->] (q_5) edge [loop right]()
(q_4) edge (q_1) edge [loop above]()
(q_5) edge (q_1) edge [loop right]();
\end{tikzpicture}
{% endlatex %}</td><td>\begin{array}lŒª_1=Œª_0P=\pmatrix{\frac15&\frac15&\frac15&\frac15&\frac15}\begin{pmatrix}\frac14 & 0 &\frac34& 0 & 0 \\ 0 &\frac13& 0 &\frac23& 0 \\ 0 & 0 &\frac12& 0 &\frac12\\\frac12&\frac16& 0 &\frac13& 0 \\\frac14& 0 &\frac12& 0 &\frac14\end{pmatrix}=\pmatrix{\frac15&\frac{1}{10}&\frac{7}{20}&\frac15&\frac{3}{20}}\\‚Ñô\left(X_2=3‚à£X_0=1\right)=\left(P^2\right)_{1,3}=\frac14‚ãÖ\frac34+\frac34‚ãÖ\frac12=\frac9{16}\end{array}</td></tr></table>
</li>
<li>
<div class="q">$N$ black balls and $N$ white balls are distributed between two urns, numbered 1 and 2 , so that each urn contains $N$ balls. At each step, one ball is chosen at random from each urn and the two chosen balls are exchanged. Let $X_n$ be the number of white balls in urn 1 after $n$ steps. Find the transition matrix for the Markov chain $X$.</div>
{% latex float:right %}\usepackage{tikz}
\usetikzlibrary{calc}
\begin{tikzpicture}[scale=0.5]
\foreach\col in {1,2,3,4}\foreach \row in {1,...,\col}{
    \fill[gray]($(0.5*\row,0)+\row*(0, {0.5*sqrt(3)})-(\col*1,0)$)circle(0.5);
    \draw($(4.5+0.5*\row,0)+\row*(0, {0.5*sqrt(3)})-(\col*1,0)$)circle(0.5);
}
\end{tikzpicture}
{% endlatex %}
<style>.table td{border:1px solid #ccc;}.table{vertical-align: top;display: inline;border-collapse: collapse;}</style>
<table class="table">
<tr><td></td><td>urn 1</td><td>urn 2</td></tr>
<tr><td>white</td><td>$X_n$</td><td>$N-X_n$</td></tr>
<tr><td>black</td><td>$N-X_n$</td><td>$X_n$</td></tr>
</table>
<table class="table">
<tr><td>chosen ball of urn 1</td><td>chosen ball of urn 2</td><td>probability</td><td>$X_{n+1}$</td></tr>
<tr><td>white</td><td>white</td><td>$X_n(N-X_n)\over N^2$</td><td>$X_n$</td></tr>
<tr><td>white</td><td>black</td><td>$X_n^2\over N^2$</td><td>$X_n-1$</td></tr>
<tr><td>black</td><td>white</td><td>$(N-X_n)^2\over N^2$</td><td>$X_n+1$</td></tr>
<tr><td>black</td><td>black</td><td>$X_n(N-X_n)\over N^2$</td><td>$X_n$</td></tr>
</table>
$\pmatrix{0&1&0&0&‚ãØ&0&0&0\\\frac1{N^2}&\frac{2(N-1)}{N^2}&\frac{(N-1)^2}{N^2}&0&‚ãØ&0&0&0\\0&\frac4{N^2}&\frac{4(N-2)}{N^2}&\frac{(N-2)^2}{N^2}&‚ãØ&0&0&0\\‚ãÆ&‚ãÆ&‚ãÆ&‚ãÆ&&‚ãÆ&‚ãÆ&‚ãÆ\\0&0&0&0&‚ãØ&\frac{(N-1)^2}{N^2}&\frac{2(N-1)}{N^2}&\frac1{N^2}\\0&0&0&0&‚ãØ&0&1&0}$
</li>
<li>
    <div class="q">A die is "fixed" so that each time it is rolled the score cannot be the same as the preceding score, all other scores having probablity $1/5$. If the first score is 6 , what are ‚Ñô($n$th score is 6) and ‚Ñô($n$th score is 1) ? [Hint: you can simplify things by selecting an appropriate state-space; do you really need a 6-state chain to answer the question?]</div>
    Group the six states into the two states: "6" and "not 6".<br>
    $P=\pmatrix{0&1\\\frac15&\frac45}$<br>
    Eigenvalues are $1,-\frac15$, corresponding eigenvectors are $\pmatrix{1\\1},\pmatrix{-5\\1}$\[P=UDU‚áíP^n=UD^nU^{-1}=\frac16\pmatrix{1+5(-5)^{-n} & 5-5(-5)^{-n}\\1-(-5)^{-n} &5+(-5)^{-n}}‚áí\pmatrix{1&0}P^{n-1}=\frac16\pmatrix{1+5(-5)^{-n+1} & 5-5(-5)^{-n+1}}\]‚à¥ ‚Ñô($n$th score is $6)=\frac{1+5(-5)^{-n+1}}6$, ‚Ñô($n$th score is $1)=\frac15$‚Ñô($n$th score is not $6)=\frac{1-(-5)^{-n+1}}6$.
</li>
<li>
    <div class="q">
        Let $X_n, n‚â•1$, be i.i.d. $‚Ñô\left(X_n=1\right)=p, ‚Ñô\left(X_n=-1\right)=1-p$, where $p‚àà(0,1)$. For each of the following, decide if $\left(Y_n\right)$ is a Markov chain. If so, find its transition probabilities.<br>
        (a) $Y_n=X_n$.<br>
        (b) $Y_n=S_n$ where $S_n=X_1+X_2+‚ãØ+X_n$.<br>
        (c) $Y_n=M_n$ where $M_n=\max \left(0, S_1, S_2, \ldots, S_n\right)$.<br>
        (d) $Y_n=M_n-S_n$.<br>
        (e) $Y_n=X_n X_{n+1}$.<br>
    </div>
    <div class="noprint">By Proposition 5.4, it suffices to find $f$ such that $Y_{n+1}=f\left(Y_n, X_{n+1}\right)$</div>
    (a) Yes. $f(Y_n,X_{n+1})=X_{n+1}$.<br>
    (b) Yes. $f(Y_n,X_{n+1})=Y_n+X_{n+1}$.<br>
    (c) No. $‚Ñô(M_4=2‚à£M_1=0,M_2=0,M_3=1)=‚Ñô(M_4=2‚à£X_1=-1,X_2=1,X_3=1)=‚Ñô(X_4=1)=p$
{% latex %}\usepackage{tikz}
\begin{tikzpicture}[scale=0.5]
\draw (0,0)node[left]{0}plot[mark=*]coordinates{(0,0)(1,-1)(2,0)(3,1)(4,2)};
\end{tikzpicture}{% endlatex %}<br>$‚Ñô(M_4=2‚à£M_1=M_2=M_3=1)=p‚Ñô(M_4=2‚à£X_1=1,X_2=-1,X_3=1)+(1-p)‚Ñô(M_4=2‚à£X_1=1,X_2=-1,X_3=-1)=p√óp+(1-p)√ó0=p^2${% latex %}\usepackage{tikz}
\begin{tikzpicture}[scale=0.5]
\draw(0,0)node[left]{0}plot[mark=*]coordinates{(0,0)(1,1)(2,0)(3,1)(4,2)};
\draw[xshift=5cm](0,0)node[left]{0}plot[mark=*]coordinates{(0,0)(1,1)(2,0)(3,-1)};
\end{tikzpicture}{% endlatex %}<br>
    (d) Yes. Since $M_{n+1}-S_{n+1}=\max\left(M_n,S_{n+1}\right)-S_{n+1}=\max\left(M_n-S_n-X_{n+1},0\right)$,
    \[f(Y_n,X_{n+1})=\max\left(Y_n-X_{n+1},0\right)\]
    (e) $p=\frac12$: Yes. We'll show $Y_i$ are independent, so $(Y_n)‚àº\text{Markov}\pmatrix{\frac12&\frac12\\\frac12&\frac12}$<br>
    $Y_n=X_nX_{n+1},Y_{n+k}=X_{n+k}X_{n+k+1},k>1$ are independent, since $X_i$ are independent. It remains to show $Y_n,Y_{n+1}$ are independent
    $$‚Ñô(Y_n=1)=‚Ñô(Y_n=-1)=‚Ñô(Y_{n+1}=1)=‚Ñô(Y_{n+1}=-1)=\frac12$$
    $$‚Ñô(Y_n=1\&Y_{n+1}=1)=‚Ñô(X_n=X_{n+1})‚Ñô(X_{n+2}=X_{n+1})=\frac14=‚Ñô(Y_n=1)‚Ñô(Y_{n+1}=1)$$
    Similarly $‚Ñô(Y_n=1\&Y_{n+1}=-1)=‚Ñô(Y_n=1)‚Ñô(Y_{n+1}=-1)$ and $‚Ñô(Y_n=-1\&Y_{n+1}=-1)=‚Ñô(Y_n=-1)‚Ñô(Y_{n+1}=-1)$.<br>
    $p‚â†\frac12$: No. $‚Ñô(X_{2n}X_{2n+1}=1‚à£X_{2n-1}X_{2n}=1,X_{2n-2}X_{2n-1}=1,‚ãØ,X_2X_1=1)=‚Ñô(X_{2n+1}=‚ãØ=X_1‚à£X_{2n}=‚ãØ=X_1)=\frac{p^{2n+1}+(1-p)^{2n+1}}{p^{2n}+(1-p)^{2n}}‚Üí\max(p,1-p)$<br>
    Since $‚Ñô(X_{2n}=-X_{2n-1}=‚ãØ=-X_1=1)=‚Ñô(X_{2n}=-X_{2n-1}=‚ãØ=-X_1=-1)$,<br>
    $‚Ñô(X_{2n}X_{2n+1}=1‚à£X_{2n-1}X_{2n}=1,X_{2n-2}X_{2n-1}=-1,‚ãØ,X_2X_1=-1)=‚Ñô(X_{2n+1}=X_{2n}‚à£X_{2n}=-X_{2n-1}=‚ãØ=-X_1)=\frac{p^n(1-p)^{n+1}+p^{n+1}(1-p)^n}{2p^n(1-p)^n}=\frac12$
</li>
<li>
    <div class="q">
        Let $C$ be a communicating class of a Markov chain. Prove the following statements:<br>
        (a) Either all states in $C$ are recurrent, or all are transient.<br>
        (b) If $C$ is recurrent then $C$ is closed.<br>(c) If $C$ is finite and closed, then $C$ is recurrent.
    </div>
    (a) if $i‚Üîj$ then $‚àÉk,m‚â•0:P^k_{ij}>0,P^m_{ji}>0$. Furthermore, for any $n‚â•0$, one way to get from $j$ to $j$ in $m+n+k$ steps is by going from $j$ to $i$ in $m$ steps, then from $i$ to $i$ in $n$ steps, and then from $i$ to $j$ in $k$ steps, thus,$$P_{jj}^{m+n+k}‚â•P_{j i}^mP_{ii}^nP_{ij}^k$$If $i$ is recurrent, by Theorem 5.8, $‚àë^‚àû_{n=0} P_{ii}^n= ‚àû$, by comparison test, $‚àë^‚àû_{n=0}P^{m+n+k}_{jj} = ‚àû$, so $‚àë^‚àû_{‚Ñì=0}P^‚Ñì_{jj} = ‚àû$, by Theorem 5.8, $j$ is recurrent.<br>
    (b) If $i‚ààC,i‚Üíj$, then $‚àÉn_0:‚Ñô_i(X_{n_0}=j)>0$. By recurrence of $i$, $‚Ñô_i(‚àÉn>n_0:X_n=i)=1$, so $‚Ñô_i(‚àÉn>n_0:X_n=i‚à£X_{n_0}=j)=1$, so $j‚Üíi$, so $C$ is closed.<br>
    (c) Start from any state from $C$. Since $C$ is closed, the chain stays in $C$ forever. If all states in $C$ are transient, then each of them is visited only finitely many times. This is impossible.
    <div class="noprint"><a href="https://www.math.ucdavis.edu/~gravner/MAT135B/materials/ch13.pdf">Proposition 13.4</a></div>
</li>
<li>
    <div class="q">
        A gambler has ¬£8 and wants to increase it to ¬£10 in a hurry. He can repeatedly stake money on the toss of a fair coin; when the coin comes down tails, he loses his stake, and when the coin comes down heads, he wins an amount equal to his stake, and his stake is returned.<br>He decides to use a strategy in which he stakes all his money if he has less than ¬£5, and otherwise stakes just enough to increase his capital to ¬£10 if he wins. For example, he will stake ¬£2 on the first coin toss, and afterwards will have either ¬£6 or ¬£10.<br>
        (a) Let ¬£$X_n$ be his capital after the $n$th coin toss. Show how to describe the sequence $\left(X_n, n‚â•0\right)$ as a Markov chain.<br>
        (b) Find the expected number of coin tosses until he either reaches ¬£10 or loses all his money.<br>
        (c) Show that he reaches ¬£10 with probability $4/5$.<br>
        (d) Show that the probability that he wins the first coin toss, given that he eventually reaches ¬£10, is $5/8$. Extend this to describe the distribution of the whole sequence $X_0, X_1, X_2, ‚Ä¶$ conditional on the event that he reaches ¬£10.<br>
        (e) Now let $\left(X_n, n ‚â• 0\right)$ be a Markov chain on ‚Ñï with $p_{0,0}=1$ and $p_{i, i+1}=p=1-p_{i, i-1}$ for $i ‚â• 1$. Let $p>1 / 2$ so that the process has an upward bias. Start at $X_0=j>0$. In lectures we showed that the probability of absorption at 0 is $\left(\frac{1-p}{p}\right)^j$. Describe the distribution of $\left(X_n, n ‚â• 0\right)$ conditional on the event of being absorbed at 0 .
    </div>
    (a) The states are $X_n=2i,i=0,1,‚ãØ,5$.\[P=\begin{pmatrix}1&0&0&0&0&0\\\frac12&0&\frac12&0&0&0\\\frac12&0&0&0&\frac12&0\\0&\frac12&0&0&0&\frac12\\0&0&0&\frac12&0&\frac12\\0&0&0&0&0&1\end{pmatrix}\]
    By Chapman-Kolmogorov equations, $‚Ñô(X_n=2i)=(P^n)_{4,i}$<br>
    (b) Let $e_i$ be the expected time if initial capital is $i$. Solving the linear equations\begin{cases}e_2=1+\frac12e_4\\e_4=1+\frac12e_8\\e_6=1+\frac12e_2\\e_8=1+\frac12e_6\end{cases}we get $e_2=e_4=e_6=e_8=2$, so $e_8=2$ is the answer.<br>Alternate solution: there is 1/2 chance of finishing game per turn (either hit 0 or 10)$‚áíe_2,e_4,e_6,e_8‚àº$Geom(1/2)$‚áíùîº[e_i]=\frac1{1-1/2}=2$<br>
    (c) Let $h_i$ be the hitting probability of 10 from $i$. Solving the linear equations
    \begin{cases}h_0=0\\h_2=\frac12h_0+\frac12h_4\\h_4=\frac12h_0+\frac12h_8\\h_6=\frac12h_2+\frac12h_{10}\\h_8=\frac12h_6+\frac12h_{10}\\h_{10}=1\end{cases}
    we get $h_i=\frac{i}{10}$. So $h_8=\frac45$.<br>
    (d) Define events: $A=${wins the first coin toss}, $B=${eventually reaches ¬£10}. By (c), $‚Ñô(B)=\frac45$. Since $A‚äÇB$,\[‚Ñô(A‚à£B)=\frac{‚Ñô(A)}{‚Ñô(B)}=\frac{1/2}{4/5}=\frac58\]Extend this to describe distribution of $X_n$:
    \[\tilde p_{ij}=\frac{‚Ñô(X_1=j\&B‚à£X_0=i)}{h_i}=\frac{‚Ñô(X_1=j‚à£X_0=i)‚Ñô(B‚à£X_1=j)}{h_i}=\frac{p_{ij}h_j}{h_i}\]
    (e) To find the hitting probability $h_i$ of 0 from $i$, we need the minimal non-negative solution to
\begin{aligned}
h_0 &=1 \\
h_i &=p h_{i+1}+q h_{i-1} \text { for } i‚â•1 .
\end{aligned}When $p>q$, has general solution$$h_i=\left(\frac{q}{p}\right)^i+\left(1-\left(\frac{q}{p}\right)^i\right)A$$
where $A$ is a constant. $h_i‚ÜíA$ as $i‚Üí‚àû$, for $h_i‚â•0\,‚àÄi$, we need $A‚â•0$. For a minimal solution, we will want $A=0, B=1$, since $1-\left(\frac{q}{p}\right)^i‚â•0\,‚àÄi$. Hence $h_i=\left(\frac{q}{p}\right)^i$.<br>
\[‚Ñô(X_n=k‚à£X_‚àû=0)=\frac{‚Ñô(X_‚àû=0‚à£X_n=k)}{‚Ñô(X_‚àû=0)}‚Ñô(X_n=k)=\left(\frac{q}{p}\right)^{j-k}(P^n)_{j,k}\]
</li>
<li>
    <div class="q">
        A Markov chain with state space $\{0,1,2,‚Ä¶\}$ is called a "birth-and-death chain" if the only non-zero transition probabilities from state $i$ are to states $i-1$ and $i+1$, except when $i=0$, where the only non-zero transition probabilities are to states 0 and 1.<br>
Consider a general birth-and-death chain and write $p_i=p_{i, i+1}$ and $q_i=p_{i, i-1}=1-p_i$. Assume that $p_i$ and $q_i$ are positive for all $i‚â•1$.<br>
Let $h_i$ be the probability of reaching 0 starting from $i$, and write $u_i=h_{i-1}-h_i$.<br>
(a) Show that $p_i h_i+q_i h_i=h_i=p_i h_{i+1}+q_i h_{i-1}$. Deduce that $u_{i+1}=\frac{q_i}{p_i} u_i$, for all $i‚â•1$.<br>
(b) Define $Œ≥_i=\frac{q_1}{p_1} \frac{q_2}{p_2}‚ãØ\frac{q_{i-1}}{p_{i-1}}$.
Write $u_i$ in terms of $Œ≥_i$ and $u_1$, and then $h_i$ in terms of $Œ≥_1, ‚Ä¶, Œ≥_i$ and $u_1$.<br>
(c) The equations for $h_1, h_2, ‚Ä¶$ may have multiple solutions. Which solution gives the true hitting probabilities? Hence find the value of $u_1$. Further assuming that $p_{0,1}>0$, deduce that the chain is transient if and only if $‚àë_{i=1}^‚àû Œ≥_i$ is finite.<br>
(d) Consider the case where
\[
p_i=\left(\frac{i+1}i\right)^2 q_i .
\]
Show that if $X_0=1$, then $‚Ñô\left(X_n‚â•1\text{ for all }n‚â•1\right)=6/œÄ^2$.
    </div>
    (a) $p_i+q_i=1‚áíp_i h_i+q_i h_i=h_i$.<br>
    $h_i=‚Ñô(X_1=i+1)‚Ñô(\text{reach 0 start from }i+1)+‚Ñô(X_1=i-1)‚Ñô(\text{reach 0 start from }i-1)=p_i h_{i+1}+q_i h_{i-1}$<br>
    $p_i h_i+q_i h_i=h_i=p_i h_{i+1}+q_i h_{i-1}‚áíp_i(h_i-h_{i+1})=q_i(h_{i-1}-h_i)‚áíu_{i+1}=\frac{q_i}{p_i} u_i$<br>
    (b) From the recurrence relation $u_{i+1}=\frac{q_i}{p_i} u_i$, we have $u_i=Œ≥_iu_1$ for $i‚â•1$, so $h_i=h_0-u_1-‚ãØ-u_i=1-(Œ≥_1+‚ãØ+Œ≥_i)u_1$<br>
    (c) The true hitting probabilities are the minimal nonnegative solutions. $h_n‚â•0‚áíu_1‚â§1/‚àë_{i=1}^n Œ≥_i‚áíu_1=1/‚àë_{i=1}^‚àû Œ≥_i$<br>
    If $‚àë_{i=1}^‚àû Œ≥_i=‚àû$ then $u_1=0‚áíh_i=1‚àÄi‚áí$recurrent<br>
    If $‚àë_{i=1}^‚àû Œ≥_i=C$ then $u_1=1/C‚áíh_0< 1‚àÄi‚áí$transient<br>
    (d) $Œ≥_i=\frac{q_1}{p_1} \frac{q_2}{p_2}‚ãØ\frac{q_{i-1}}{p_{i-1}}=\frac{1^2}{2^2}\frac{2^2}{3^2}‚ãØ\frac{(i-1)^2}{i^2}=\frac1{i^2}‚áíu_1=1/‚àë_{i=1}^‚àû\frac1{i^2}=\frac6{œÄ^2}$
</li>
</ol>
