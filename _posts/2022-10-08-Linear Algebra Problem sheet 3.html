---
mathjax: true
tag: Linear Algebra
excerpt: sheet 3 ‚Äî MT 2022
---
<style>div.noprint{border: solid 1px black;padding: 5px; width: max-content;max-width: 99%;}</style>
<ol>
<li>
    Consider the matrix
    $$
    A=\pmatrix{
    0 & 2 & -1 \\
    -2 & 3 & -2 \\
    -3 & 2 & -2
   }$$
   <ol type="i">
    <li>Find the characteristic polynomial $\chi_A(x)$ and show it is of the form $-\left(x-Œª_1\right)\left(x-Œª_2\right)^2$ for some $Œª_1 \neq Œª_2$.</li>
    <li>Find basis vectors $u$ of $\ker\left(A-Œª_1 I\right), v_1$ of $\ker\left(A-Œª_2 I\right)$ and $v_1, v_2$ of $\ker\left(A-Œª_2 I\right)^2$</li>
    <li>Explain why $\left(A-Œª_2 I\right)v_2$ is a scalar multiple of $v_1$.</li>
    <li>Find the matrix of the linear transformation $A$ with respect to the new basis $v_1, v_2, u$.</li></ol>
    <b>Solution.</b><ol type="i">
    <li>$\chi_A(x)=\det(xI-A)=-(x+1)(x-1)^2‚áíŒª_1=-1,Œª_2=1$</li>
    <li>$A-Œª_1I=A+I=\pmatrix{
             1 & 2 & -1 \\
             -2 & 4 & -2 \\
             -3 & 2 & -1
            }‚áí\ker\left(A-Œª_1 I\right)=‚ü®u‚ü©,u=\pmatrix{0\\1\\2}$<br>
    $A-Œª_2I=A-I=\pmatrix{
         -1 & 2 & -1 \\
         -2 & 2 & -2 \\
         -3 & 2 & -3}‚áí\ker\left(A-Œª_2 I\right)=‚ü®v_1‚ü©,v_1=\pmatrix{1\\0\\-1}$<br>
    $(A-Œª_2I)^2=\pmatrix{
         0 & 0 & 0 \\
         4 & -4 & 4 \\
         8 & -8 & 8}‚áí\ker\left(A-Œª_2 I\right)^2=‚ü®v_1,v_2‚ü©,v_2=\pmatrix{1\\1\\0}$</li>
    <li>$v_2‚àà\ker\left(A-Œª_2 I\right)^2‚áí\left(A-Œª_2 I\right)\big(\left(A-Œª_2 I\right)v_2\big)=0‚áí\left(A-Œª_2 I\right)v_2‚àà\ker\left(A-Œª_2 I\right)‚áí\left(A-Œª_2 I\right)v_2$ is a scalar multiple of $v_1$.</li>
<li>$Av_1=v_1,Av_2=v_1+v_2,Au=-u$, so the matrix of $A$ with respect to the basis $v_1,v_2,u$ is $\pmatrix{1&1&0\\0&1&0\\0&0&-1}$<br>Calculate inverse matrix: $P=(v_1,v_2,u)=\pmatrix{1&1&0\\0&1&1\\-1&0&2},P^{-1}AP=\pmatrix{1&1&0\\0&1&0\\0&0&-1}$</li></ol>
</li>
<li>Write down all possible Jordan normal forms for matrices with characteristic polynomial $(x-Œª)^5$. In each case, calculate the minimal polynomial and the geometric multiplicity of the eigenvalue $Œª$. Verify that this information determines the Jordan normal form for this choice of characteristic polynomial.<br>
    <b>Solution.</b><br>
    There are 7 partitions of 5 into positive integers, up to permutation.
    <style>
        #demo {
            border-collapse:collapse;
            padding:5px;
        }
        #demo th {
            border:1px solid #C0C0C0;
            padding:5px;
            background:#F0F0F0;
        }
        #demo td {
            border:1px solid #C0C0C0;
            padding:5px;
        }
    </style>
    <table id="demo">
        <thead>
        <tr>
            <th>size of Jordan blocks<br></th>
            <th>minimal polynomial</th>
            <th>geometric multiplicity of Œª</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>5<br></td>
            <td>$(x-Œª)^5$</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4+1<br></td>
            <td>$(x-Œª)^4$</td>
            <td>2</td>
        </tr>
        <tr>
            <td>3+2+1<br></td>
            <td>$(x-Œª)^3$</td>
            <td>3<br></td>
        </tr>
        <tr>
            <td>3+1+1+1<br></td>
            <td>$(x-Œª)^3$</td>
            <td>4<br></td>
        </tr>
        <tr>
            <td>2+2+1<br></td>
            <td>$(x-Œª)^2$</td>
            <td>3<br></td>
        </tr>
        <tr>
            <td>2+1+1+1<br></td>
            <td>$(x-Œª)^2$</td>
            <td>4<br></td>
        </tr>
        <tr>
            <td>1+1+1+1+1<br></td>
            <td>$x-Œª$</td>
            <td>5<br></td>
        </tr>
        <tbody>
    </table>
    No two rows have identical entries in both the second and the third column, so this information determines the Jordan normal form for this choice of characteristic polynomial.
</li>
<li>
    Prove that every square matrix over the complex numbers is conjugate to its transpose, i.e. prove that given any $(n √ó n)$-matrix $A$ there exists an $(n √ó n)$-matrix $P$ such that $P^{-1} A P=A^{\sf T}$ where $A^{\sf T}$ is the transpose of $A$.<br>
    <b>Proof.</b><br>
    Let the Jordan form of $A$ be $J$, then $A$ is conjugate to $J$. Let the Jordan blocks of $J$ be $J_1,‚Ä¶,J_‚Ñì$. For each $i=1,‚Ä¶,l$, let
$$B_i = \begin{bmatrix}&&&1 \\&&1\\&‚ã∞\\1\end{bmatrix} \qquad \text{and} \qquad J_i = \begin{bmatrix}Œª&1\\&‚ã±&‚ã±\\&&Œª&1\\&&&Œª\end{bmatrix}$$
Conjugation by $B_i$ is flipping the matrix vertically and horizontally, which is equivalent to rotating the matrix 180¬∞. Rotate $J_i^{\sf T}$ we get $J_i$, so $B_i^{-1}J_i^{\sf T}B_i=J_i$. Let $B=\operatorname{diag}(B_1,B_2,‚Ä¶,B_‚Ñì)$. Then $B^{-1}J^{\sf T}B=J$. Therefore, $J$ is conjugate to $J^{\sf T}$. Also $J^{\sf T}$ is conjugate to $A^{\sf T}$, by transitivity $A$ is conjugate to $A^{\sf T}$.
</li>
<li>Let $\left\{e_1, e_2, e_3\right\}$ be the usual basis $\left\{(1,0,0)^{\sf T},(0,1,0)^{\sf T},(0,0,1)^{\sf T}\right\}$ of $\mathbb{R}^3$. Express the dual basis to $\left\{(1,0,0)^{\sf T},(1,-1,1)^{\sf T},(2,-4,7)^{\sf T}\right\}$ in terms of $e_1', e_2', e_3'$.<br>
    <b>Proof.</b><br>
    Let $\{v_1,v_2,v_3\}$ be a basis. To find the dual basis $\{v_1',v_2',v_3'\}$, we need $v_i'(v_j)=Œ¥_{ij}‚áî\pmatrix{v_1'\\v_2'\\v_3'}\pmatrix{v_1&v_2&v_3}=I$. So we invert the matrix $\pmatrix{v_1&v_2&v_3}$ and read by row.
$$\pmatrix{1 & 1 & 2 \\0 & -1 & -4 \\0 & 1 & 7}^{-1}=\pmatrix{
 1 & \frac{5}{3} & \frac{2}{3} \\
 0 & -\frac{7}{3} & -\frac{4}{3} \\
 0 & \frac{1}{3} & \frac{1}{3}}$$So the dual basis to $\left\{(1,0,0)^{\sf T},(1,-1,1)^{\sf T},(2,-4,7)^{\sf T}\right\}$ is $\left\{e_1'+\frac53e_2'+\frac23e_3',-\frac73e_2'-\frac43e_3',\frac13e_2'+\frac13e_3'\right\}$.
 <div class="noprint"><a href="Examples">biorthogonal</a><br>
 In 3-dimensional Euclidean space, for a given basis $\{e_1, e_2, e_3\}$, you can find the biorthogonal (dual) basis $\{e_1, e_2, e_3\}$ by formulas below: 
 \begin{align*}
 \mathbf{e}^1 = \left(\frac{\mathbf{e}_2 \times \mathbf{e}_3}{V}\right)^\mathsf{T}\\ 
 \mathbf{e}^2 = \left(\frac{\mathbf{e}_3 \times \mathbf{e}_1}{V}\right)^\mathsf{T}\\ 
 \mathbf{e}^3 = \left(\frac{\mathbf{e}_1 \times \mathbf{e}_2}{V}\right)^\mathsf{T}
 \end{align*}</div>
</li>
<li>
    Let $T:V‚ÜíW$ be a linear map between finite-dimensional vector spaces. Prove that
    $$
    \operatorname{Im}\left(T'\right)=(\ker T)^0.
    $$
    <b>Proof.</b>
    <div class="noprint">
        <a href="https://en.wikipedia.org/wiki/Fredholm%27s_theorem">Fredholm's theorem</a> in linear algebra is as follows: if $M$ is a matrix, then the orthogonal complement of the row space of $M$ is the null space of $M$:
\[(\operatorname{row } M)^\bot = \ker M.\]
Similarly, the orthogonal complement of the column space of $M$ is the null space of the adjoint:
\[(\operatorname{col } M)^\bot = \ker M^*.\]
<hr><a href="https://pillowmath.github.io/Math%20255A%27/Lec14.pdf">Math 255A</a><br>
Proposition 1.5. Let $A \in \mathcal{B}(X, Y)$. Then $\ker A^*=(\operatorname{ran} A)^‚üÇ$, and $\ker A={}^‚üÇ\left(\operatorname{ran} A^*\right)$.<br>
Proof. We prove the second one; the first is similar. We have
\begin{aligned}
x‚àà\ker A&‚áîA x=0 \\
&‚áî\left< A x, y^*\right>=0 \quad ‚àÄy^* \in Y^* \\
&‚áî\left< x, A^* y^*\right>=0 \quad ‚àÄy^* \in Y^* \\
&‚áî x ‚àà{}^‚üÇ\left(\operatorname{ran} A^*\right) .
\end{aligned}
    </div>
    $‚àÄf‚ààW',\ v ‚àà\ker T:Tv=0‚áíT'(f)(v)=f(Tv)=f(0)=0 ‚áíT'(f)‚àà(\ker T)^0$. Therefore $\operatorname{Im}\left(T'\right)‚äÇ(\ker T)^0$.<br>
    $‚àÄf‚àà(\ker T)^0$, the quotient map $\bar f‚àà(V/\ker T)'$ is given by $\bar f(v+\ker T)=f(v)$. By first isomorphism theorem, we have an isomorphism $g:\operatorname{Im}T‚ÜíV/\ker T$.<br>Then $\bar f(g(T(v)))=f(v)‚áíf=T'(\bar f‚àòg)‚àà\operatorname{Im}\left(T'\right)$. Therefore $\operatorname{Im}\left(T'\right)‚äÉ(\ker T)^0$.
</li>
<li>Let $U$ be a subspace of $V$. Show that restriction $f‚Ü¶\left.f\right|_U$ defines a linear map $V' ‚Üí U'$. Deduce that there is a natural injection $V' / U^0 ‚Üí U'$ which is an isomorphism when $V$ is finite-dimensional.<div class="noprint"><a href="Bath MA20216 Fran Burstall/M216.09.html#qu:M216.09:6">restriction map is dual to inclusion map</a></div>
    <b>Proof.</b><br>
    $‚àÄf,g ‚àà V',\ u‚ààU,\ \left.(f+Œªg)\right|_U(u)=f(u)+Œªg(u)=\left(\left.f\right|_U+Œª\left.g\right|_U\right)(u)‚áí\left.(f+Œªg)\right|_U=\left.f\right|_U+Œª\left.g\right|_U$, so $f‚Ü¶\left.f\right|_U$ is a linear map. By definition the kernel is $U^0$. By the first isomorphism theorem, the image is isomorphic to  $V'/U^0$, thus giving us an injection $V'/U^0\to U'$.<br>Let $V$ be finite dimensional. For any $œà‚ààU'$, define $f‚ààV'$ as $f(v)=œà(\text{proj}_Uv)$, then $\left.f\right|_U=œà$. We conclude that the restriction is surjective.
</li>
<li>
    (i) Let $V$ be a finite dimensional vector space over $ùîΩ$. For a linear transformation $T: V ‚Üí V$ define the trace $\operatorname{tr}(T)$ to be the trace of the matrix representing $T$ with respect to some basis of $V$. Show that $\operatorname{tr}(T)$ is well-defined, i.e. show that it is independent of choice of basis.<br>
    (ii) As usual let $\operatorname{Hom}(V, V)$ denote the space of linear maps from $V$ to itself. For $S‚àà\operatorname{Hom}(V, V)$ define $f_S:\operatorname{Hom}(V, V)‚ÜíùîΩ$ by
    $$
    f_S: T‚Ü¶\operatorname{tr}(S‚àòT)
    $$
    Show that $S‚Ü¶f_S$ defines a linear isomorphism between $\operatorname{Hom}(V, V)$ and its dual that does not depend on a choice of basis.<div class="noprint"><a href="https://en.wikipedia.org/wiki/Character_theory">Character theory</a></div>
    <b>Solution.</b><br>
    (i) Let $M$ be the matrix of $T$ with respect to some basis of $V$. Then the matrix of $T$ with respect to any basis of $V$ is of the form $P^{-1}MP$. By the cyclic property of trace, $\operatorname{tr}(P^{-1}MP)=\operatorname{tr}(PP^{-1}M)=\operatorname{tr}M$. So  it is independent of choice of basis.<br>
    (ii) $‚àÄS,S',T,T'‚àà\operatorname{Hom}(V, V),\ f_S(T+ŒªT')=\operatorname{tr}\big(S‚àò(T+ŒªT')\big)=\operatorname{tr}(S‚àòT+ŒªS‚àòT')=\operatorname{tr}(S‚àòT)+Œª\operatorname{tr}(S‚àòT')=f_S(T)+Œªf_S(T')‚áíf_S$ is linear.<br>
    $f_{S+ŒªS'}(T)=\operatorname{tr}\big((S+ŒªS')‚àòT\big)=\operatorname{tr}(S‚àòT+ŒªS'‚àòT)=\operatorname{tr}(S‚àòT)+Œª\operatorname{tr}(S'‚àòT)=(f_S+Œªf_{S'})(T)‚áíf_{S+ŒªS'}=f_S+Œªf_{S'}‚áí$the map $S ‚Ü¶ f_S$ is linear.<br>
    Suppose $f_S=0$. Let $M$ be the matrix for $S$. Let $E_{ji}$ be the matrix (of same dimension as $M$) whose only non-zero entry is 1 at position $(j,i)$. $‚àÄi,j:M_{ij}=\operatorname{tr}(ME_{ji})=0‚áíM=0‚áíS=0$. Therefore $S‚Ü¶f_S$ is injective. Since the dimension of $\operatorname{Hom}(V, V)$ is equal to the dimension of its dual, $S‚Ü¶f_S$ is an isomorphism.<br>
    By (i), $S‚Ü¶f_S$ does not depend on a choice of basis.
</li>
<li>
    Let $T: V ‚Üí W$ be a map between finite-dimensional vector spaces and let $T'': V'' ‚Üí W''$ be the associated map between double duals.
    Show that under the natural identifications between spaces and their double duals, $T''$ is identified with $T$. That is, if $E^{(V)}:V‚âÖV''$ and $E^{(W)}:W‚âÖW''$ are the natural isomorphisms, then we have
    $$
    T''‚àòE^{(V)}=E^{(W)}‚àòT.
    $$
    <b>Proof.</b><div class="noprint"><a href="https://en.wikipedia.org/wiki/Natural_transformation#Double_dual_of_a_vector_space">Natural transformation#Double dual of a vector space</a><br><a href="https://en.wikipedia.org/wiki/Natural_transformation#Example:_dual_of_a_finite-dimensional_vector_space">Example: dual of a finite-dimensional vector space</a><br>Take $W=V$ and $T$ be a change of basis, this question implies $E^{(V)}$ is independent of a choice of basis</div>
    $‚àÄv‚ààV,f‚ààV',\ (T''‚àòE^{(V)})(v)(f)=E^{(V)}(v)\big(T'(f)\big)=(f‚àòT)(v)$<br>
    $(E^{(W)}‚àòT)(v)(f)=E^{(W)}\big(T(v)\big)(f)=(f‚àòT)(v)$<br>
    Therefore $T''‚àòE^{(V)}=E^{(W)}‚àòT$.
</li>
<li>Let $V$ be finite dimensional. A hyperplane in $V$ is defined as the kernel of a linear functional.<br>Show that every subspace of $V$ is the intersection of hyperplanes.<br>
    <b>Proof.</b><br>
    Let $W$ be a subspace of $V$. $‚àÄx‚ààV‚àñW,‚àÉŒ¶(x)‚ààV'$ such that $Œ¶(x)|_W= 0$ and $Œ¶(x)(x)=1$. Then $W = \bigcap_{x‚àâW} \ker Œ¶(x)$.<br><br>
    Show that every subspace of $V$ is the <i>finite</i> intersection of hyperplanes.<br>
    <b>Proof.</b><br>
    Let ‚Ñ¨ be a basis of $W^0$. Then $W = \bigcap_{f‚àà‚Ñ¨} \ker f$.
</li></ol>
