---
mathjax: true
tag: Linear Algebra
excerpt: College exam questions
---
<ol>
<li><p style="margin-top: 0.5em"> <font style="font-size: 84.1%"><strong>Problem 1. </strong><a id="p1"></a>Let \(U\) be a subspace of a vector space \(V\). Let \(V / U\) denote the quotient space and \(π : V→V / U\) the natural linear transformation. Prove that if \(W\) is a subspace of \(V / U\) then \(π^{- 1}W\) is a subspace of \(V\), and that if \(V\) is finite-dimensional then</font> </p><p style="margin-bottom: 0.5em"> <font style="font-size: 84.1%">\[\dim π^{- 1}W=\dim U + \dim W\]</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>Since \(W\) is a subspace of \(V / U\), \(\forall λ, \forall v_1, v_2 \in π^{- 1}W\), </p>\[π \left({v_1}\right), π (v_2) \in W \Rightarrow π (λ v_1 + v_2)=λ π \left({v_1}\right) + π (v_2) \in W \Rightarrow λ v_1+ v_2 \in π^{- 1}W\] <p> So \(π^{- 1}W\) is a subspace of \(V\). </p><p style="margin-bottom: 1em"> Image and kernel of \(π |_{π^{- 1}W}\) is \(W\) and \(U\), by rank-nullity theorem, \(\dim π^{- 1}W=\dim U + \dim W\).<span style="margin-left: 1em"></span>\(\Box\) </p><p style="margin-top: 0.5em; margin-bottom: 0.5em"> <font style="font-size: 84.1%"><strong>Problem 2. </strong>Suppose that \(V\) is a complex vector space of dimension \(n\) and that \(T : V→V\) is a linear transformation. Prove that there exist \(T\)-invariant subspaces \(V_1 \subseteq V_2 \subseteq \ldots \subseteq V_n\) of \(V\) with \(\dim V_i=i\) for each \(i=1, 2, \ldots, n\). Indicate briefly how to deduce a matrix version of this result.</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>Induct on \(n\). Since \(\mathbb{C}\) is algebraically closed, \(T\) has an eigenvalue λ. Let \(v\) be a λ-eigenvector, then \(V / \langle v \rangle\) is \(T\)-invariant and \(n - 1\) dimensional.<br>By induction hypothesis, there exist \(T\)-invariant subspaces \(W_1 \subseteq W_2 \subseteq \ldots \subseteq W_{n - 1}\) of \(\)\(V / \langle v \rangle\). Using <a href="#p1">Problem 1</a> for \(i=2, \ldots, n\) define \(V_i=π^{- 1}W_{i - 1}\), then </p>\[\dim V_i=\dim W_{i - 1}+ \dim \langle v \rangle=(i - 1) + 1=i\] <p style="margin-bottom: 1em"> Let \(V_1=\langle v \rangle\), then \(\dim V_1=1\) and \(V_1 \subseteq V_2=π^{- 1}W_1\).<span style="margin-left: 1em"></span>\(\Box\) </p><p> A matrix version of this result: <a href="https://en.wikipedia.org/wiki/Schur_decomposition#Proof">Wikipedia</a> </p><div style="margin-top: 0.5em; margin-bottom: 0.5em; margin-left: 70.291740657624px; margin-right: 70.291740657624px"><p> The above argument can be slightly restated as follows: let <i>λ</i> be an eigenvalue of <i>A</i>, corresponding to some eigenspace <i>V<sub>λ</sub></i>. <i>A</i> induces an operator <i>T</i> on the <a href="https://en.wikipedia.org/wiki/Quotient_space_(linear_algebra)">quotient space</a> <b>C</b><sup><i>n</i></sup>/<i>V<sub>λ</sub></i>. This operator is precisely the <i>A</i><sub>22</sub> submatrix from above. As before, <i>T</i> would have an eigenspace, say <i>W<sub>μ</sub></i> &sub; <b>C</b><sup><i>n</i></sup> modulo <i>V<sub>λ</sub></i>. Notice the preimage of <i>W<sub>μ</sub></i> under the quotient map is an <a href="https://en.wikipedia.org/wiki/Invariant_subspace">invariant subspace</a> of <i>A</i> that contains <i>V<sub>λ</sub></i>. Continue this way until the resulting quotient space has dimension 0. Then the successive preimages of the eigenspaces found at each step form a flag that <i>A</i> stabilizes. </p></div><p style="margin-top: 0.5em"> <font style="font-size: 84.1%"><strong>Problem 3. </strong>Suppose that \(A=(a_{ij})\) is a complex \(n \times n\) matrix with (not necessarily distinct) eigenvalues \(λ_1, λ_2, \ldots, λ_n\) Prove that</font> </p><p style="margin-bottom: 0.5em"> <font style="font-size: 84.1%">\[\sum_{i=1}^n \sum_{j=1}^n a_{ij}a_{ji}=\sum_{k=1}^n λ_k^2 \]</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>Because the eigenvalues of \(A^2\) are \(λ_k^2\), </p>\[\sum_{i=1}^n \sum_{j=1}^n a_{ij}a_{ji}=\operatorname{Tr}A^2=\sum_{k=1}^n λ_k^2 \] <p> Be careful: the eigenvalues of \(A^{\dagger}A\) are not \(\)\(| λ_k |^2\), </p>\[\operatorname{Tr}A^{\dagger}A{\color{red}{\neq}}\sum_{k=1}^n | λ_k|^2\]<p style="margin-bottom: 1em"> <a href="http://kuing.infinityfreeapp.com/forum.php?mod=viewthread&tid=10127">See this thread</a><span style="margin-left: 1em"></span>\(\Box\) </p></li>
<li><p> <font style="font-size: 84.1%"><strong>Problem 1. </strong>Given a finite-dimensional real inner product space \(V\) with inner product ⟨,⟩ and a transformation \(T : V→V\), show that there is a unique linear transformation \(T^*: V→V\) satisfying</font> </p><p style="margin-bottom: 0.5em"> <font style="font-size: 84.1%">\[⟨T^*u, v⟩=⟨u, Tv⟩\quad \text{ for all }u, v \in V\]</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>(Uniqueness) See <a href="https://courses.maths.ox.ac.uk/pluginfile.php/30064/mod_resource/content/2/A0.pdf#page=42">Lemma 8.14</a>: Let \(\tilde{T}\) be another map satisfying (*). Then for all \(v, w \in V\) </p>\begin{align*}⟨T^*(v) - \tilde{T}(v), w⟩&=⟨T^*(v), w⟩-⟨\tilde{T}(v), w⟩\\ &=⟨v, T (w)⟩-⟨v, T (w)⟩\\ &=0.\end{align*}<p> But ⟨,⟩ is non-degenerate and hence for all \(v \in V\) </p>\[ T^*(v) - \tilde{T}(v)=0,\] <p> and so \(T^*=\tilde{T}\). </p><p> (Existence) See <a href="https://courses.maths.ox.ac.uk/pluginfile.php/30064/mod_resource/content/2/A0.pdf#page=42">Theorem 8.15</a>: Let \(v \in V\) and consider the map \(V→\mathbb{R}\) given by </p>\[ w \mapsto⟨v, T (w)⟩.\] <p> Then \(⟨v, T (·)⟩\) is a linear functional as \(T\) is linear and as ⟨,⟩ is linear in the second coordinate. As \(V\) is finite dimensional, \(\phi : V→V'\) given by \(\phi (u)=⟨u,·⟩\) is an \(\mathbb{R}\)-linear isomorphism, and in particular a surjective map. Thus there exists \(u \in V\) such that </p>\[⟨v, T (·)⟩=⟨u,·⟩\] <p> Defining \(T^*(v) :=u\) we therefore have </p>\[⟨v, T (·)⟩=⟨T^*(v),·⟩\text{, i.e., }⟨v, T (w)⟩=⟨T^*(v), w⟩\text{ for all }w \in V.\] <p> To see that \(T^*\) is linear, note that for all \(v_1, v_2, w \in V, λ\in ℝ\), </p>\begin{align*}⟨T^*(v_1 + λv_2), w⟩&=⟨v_1 + λv_2, T (w)⟩\\ &=⟨v_1, T (w)⟩+ λ⟨v_2, T (w)⟩\\ &=⟨T^*(v_1), w⟩+ λ⟨T^*(v_2), w⟩\\ &=⟨T^*(v_1) + λT^*(v_2), w⟩.\end{align*}<p> (These equalities have nothing to do with our actual definition of \(T^*\), but just follow from the fact that by construction it satisfies \(⟨v, T (w)⟩=⟨T^*(v), w⟩\) for all \(v, w \in V\).) As ⟨,⟩ is non-degenerate (equivalently, as \(\phi\) is injective) </p><p style="margin-bottom: 1em"> \[ T^*(v_1 + λv_2)=T^*(v_1) + λT^*(v_2) .\] <span style="position: absolute;right: 1em;">\(\Box\)</span></p><p style="margin-top: 0.5em"> <font style="font-size: 84.1%"><strong>Problem 2. </strong>Now let \(V\) be the vector space of all \(n \times n\) real matrices with the usual addition and scalar multiplication. For \(A, B\) in \(V\), let</font> </p><p> <font style="font-size: 84.1%">\[⟨A, B⟩=\operatorname{Tr}(A^t B),\]</font> </p><p style="margin-bottom: 0.5em"> <font style="font-size: 84.1%">where \(A^t\) denotes the transpose of \(A\). Show that this defines an inner product on \(V\). Let \(P\) be an invertible \(n \times n\) matrix and let \(θ: V→V\) be the linear transformation given by \(θ(A)=P^{-1}AP\). Find the adjoint \(θ^*\) of \(θ\).</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>Easy to show ⟨,⟩ is bilinear and symmetric. </p>\[⟨A, A⟩=\operatorname{Tr}(A^t A)=\sum_{i, j}A_{i, j}^2\geqslant 0 \text{ and }=0 \text{ iff }A=0\] <p> So ⟨,⟩ is positive definite. So ⟨,⟩ is an inner product on \(V\). </p>\begin{align*}⟨θ^*A, B⟩&=⟨A,θB⟩\\ &=\operatorname{Tr}(A^t (P^{-1}BP))\\{\small \text{By cyclic property of Tr}}&=\operatorname{Tr}((PA^t P^{-1}) B)\\ &=\operatorname{Tr}(((P^t)^{-1}AP^t)^t B)\\ &=⟨(P^t)^{-1}AP^t, B⟩\end{align*}<p style="margin-bottom: 1em"> So \(θ^*(A)=(P^t)^{-1}AP^t\).<span style="margin-left: 1em"></span>\(\Box\) </p><p style="margin-top: 0.5em; margin-bottom: 0.5em"> <font style="font-size: 84.1%"><strong>Problem 3. </strong>Prove also that \(θ\) is self-adjoint if and only if \(P\) is either symmetric or skew-symmetric.</font> </p><p style="margin-top: 1em"> <strong>Proof. </strong>If \(P\) is symmetric, \(θ^*(A)=P^{-1}AP=(P^t)^{-1}AP^t=θ(A)\); if \(P\) is skew-symmetric, \(θ^*(A)=P^{-1}AP=(- P^t)^{-1}A (- P^t)=(P^t)^{-1}AP^t=θ(A)\). </p><p> \(θ^*=θ⇒∀A \in V : (P^t)^{-1}AP^t=P^{-1}AP⇒∀A \in V : A (P^t P^{-1})=(P^t P^{-1}) A\) </p><p> Since the center of \(\operatorname{GL}(n, \mathbb{R})\) is scalar matrices, \(P^t P^{-1}=λI⇒P^t=λP\) for some \(λ\in \mathbb{R}\). Taking det, </p>\[ λ^n=\det (λI)=\det (P^t P^{-1})=\det (P^t) \det (P^{-1})=\det (P) \det (P^{-1})=1\] <p style="margin-bottom: 1em"> So \(λ=\pm 1\). \(P\) is either symmetric or skew-symmetric.<span style="margin-left: 1em"></span>\(\Box\) </p></li>
</ol>
